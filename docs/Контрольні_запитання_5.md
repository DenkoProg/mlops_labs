# Контрольні запитання - Відповіді (Лабораторна робота №5)

## 1. Опишіть три рівні зрілості MLOps (Google Maturity Model)

| Рівень | Назва | Ключова ознака |
|---|---|---|
| **0** | Ручний процес | Notebooks, ручна передача артефактів, немає відтворюваності |
| **1** | Автоматизація ML-пайплайну (CT) | Оркестрований пайплайн, Continuous Training за розкладом/подіями |
| **2** | Повна CI/CD + CT інтеграція | Код пайплайну проходить через CI/CD, моделі — через CT, є моніторинг drift |

**Наш проект після ЛР5** знаходиться між рівнями 1 та 2: є CT через Airflow DAG (@weekly), CI через GitHub Actions, але немає моніторингу drift у production.

---

## 2. Що таке DAG в контексті Airflow? Чому «ациклічний»?

**DAG (Directed Acyclic Graph)** — орієнтований ациклічний граф, де:
- **Вузли** — задачі (Tasks)
- **Ребра** — залежності між ними

**Ациклічний** означає: неможливо, стартувавши з будь-якого вузла, повернутися до нього, рухаючись по ребрах. Це гарантує, що пайплайн завершиться і не зависне у нескінченному циклі.

У нашому DAG (`ml_training_pipeline`):
```
prepare_data → train_model → evaluate_model → register_model
```
Якщо б `register_model` залежав від `prepare_data`, утворився б цикл — Airflow відхиляє такі DAG-и при завантаженні.

---

## 3. Навіщо multi-stage build у Docker для ML-проєктів?

**Проблема:** наївний образ із `uv`, компілятором C (для numpy/scikit), заголовками Python важить >1.5GB.

**Multi-stage вирішує це:**

```dockerfile
# Stage 1: builder — є всі build-tools
FROM python:3.11-slim AS builder
RUN pip install uv
RUN uv sync --frozen --no-dev   # компілює бінарні залежності

# Stage 2: runtime — тільки результат
FROM python:3.11-slim AS runtime
COPY --from=builder /app/.venv /app/.venv  # копіюємо готовий venv
COPY src/ ./src/
# ↑ немає uv, gcc, заголовків → образ ~400MB замість ~1.5GB
```

**Переваги для ML/CI:**
- Швидше завантаження образу в CI-runner
- Менша поверхня атаки (немає build-tools у production)
- Layer cache: якщо `pyproject.toml` не змінився — залежності не перебудовуються

---

## 4. Поясніть ключові компоненти Apache Airflow

| Компонент | Роль |
|---|---|
| **Scheduler** | Інтерпретує DAG, відстежує стан задач, ініціює запуск за розкладом |
| **Executor** | Стратегія виконання (LocalExecutor — у процесі; CeleryExecutor — розподілено) |
| **Webserver** | UI на http://localhost:8080: перегляд DAG, логів, ручний запуск |
| **Metadata DB** | PostgreSQL/SQLite: стан всіх runs, tasks, конфігурація |
| **Worker** | Процес/контейнер, що виконує код задачі |

У нашому `docker-compose.yml` використовується **LocalExecutor + PostgreSQL** — найпростіший production-ready варіант без зайвої складності Celery.

---

## 5. Що таке Continuous Training (CT) і чим воно відрізняється від CI?

**CI (Continuous Integration)** — автоматична перевірка *коду*: лінтинг, тести, DVC pipeline validation. Запускається при кожному `git push`.

**CT (Continuous Training)** — автоматичне *перенавчання моделі* за розкладом або подіями (нові дані, data drift). Запускається незалежно від змін коду.

| | CI | CT |
|---|---|---|
| **Тригер** | `git push` / `pull_request` | `@weekly` / нові дані / drift alert |
| **Артефакт** | Статус тестів, CML report | Нова версія моделі |
| **Інструмент (ЛР5)** | GitHub Actions | Airflow DAG |

**Разом** вони утворюють рівень 2 MLOps: CI перевіряє код пайплайну, CT оновлює модель.

---

## 6. Яку роль грає `register_model.py` в пайплайні?

Реалізує **якісний поріг для просування моделі** (promotion gate):

```python
current_f1 = get_current_champion_f1(client)  # з MLflow Registry

if new_f1 <= current_f1:
    log.info("Not better than champion. Skipping.")
    return

# Якщо краща — реєструємо та призначаємо аліас
mlflow.sklearn.log_model(model, registered_model_name="chest_xray_rf")
client.set_registered_model_alias("chest_xray_rf", "champion", latest.version)
```

**Чому аліас `champion`?** Аліаси стабільніші за номери версій — клієнти inference завжди завантажують `champion`, не прив'язуючись до `v5`, `v6` і т.д.

---

## 7. Чому тести DAG-ів важливо запускати у CI без живого Airflow?

DAG-тести перевіряють **структуру** графа, а не виконання задач. Запуск повного Airflow у CI вимагає PostgreSQL, Scheduler, Webserver — це дорого (час + ресурси).

Наш підхід у `tests/test_dag.py`:
```python
# Імпортуємо DAG-модуль безпосередньо, без Airflow runtime
spec = importlib.util.spec_from_file_location("ml_pipeline_dag", DAG_PATH)
module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(module)
dag = module.dag
```

Це дає **швидкий зворотний зв'язок** (1 сек vs. 2+ хв) при:
- Синтаксичні помилки в DAG-файлі
- Неправильний порядок задач або відсутня залежність
- Неправильний `dag_id` або `schedule`

---

## 8. Як Airflow забезпечує відтворюваність CT-запусків?

1. **`catchup=False`** — не виконує пропущені запуски за минулі тижні (уникаємо лавини runs)
2. **`start_date` фіксований** — детермінований розклад
3. **Retries + retry_delay** — автоматичне повторення при збоях (мережа, DVC pull)
4. **Логи кожного run** зберігаються в Airflow Metadata DB — повна аудит-стежка
5. **DVC lock у Git** — `dvc repro` у `train_model` tasks завжди тренує на тій версії даних, що зафіксована в `dvc.lock` поточного коміту
6. **MLflow run_id** — кожна реєстрація пов'язана з конкретним `run_id`, що Contains commit hash, params, metrics

---

## 9. Що таке XComs в Airflow? Які обмеження на передачу даних і чому не варто передавати великі датасети?

**XComs (Cross-Communications)** — механізм обміну невеликими повідомленнями між tasks в межах одного DAG run через Airflow Metadata DB.

```python
# Task 1: push значення
def evaluate_model(**kwargs):
    metrics = {"f1": 0.90, "accuracy": 0.91}
    kwargs["ti"].xcom_push(key="metrics", value=metrics)
    return metrics  # автоматично → XCom з key="return_value"

# Task 2: pull значення
def register_model(**kwargs):
    metrics = kwargs["ti"].xcom_pull(
        task_ids="evaluate_model", key="metrics"
    )
    if metrics["f1"] > 0.85:
        ...
```

**Обмеження:**
- XComs зберігаються в **Metadata DB** (SQLite/PostgreSQL) → ліміт за розміром (~48KB для SQLite).
- Передача великих об'єктів (DataFrame, numpy array) зробить БД непридатною до використання.
- **Правило:** через XComs передавати лише **метадані** (метрики, шляхи до файлів, run_id). Самі дані/артефакти — через файлову систему або S3/DVC remote.

---

## 10. Яка різниця між Sensor і звичайними операторами? Приклад у MLOps

| | **Sensor** | **Звичайний оператор (Task)** |
|---|---|---|
| **Призначення** | Чекати на умову (файл, HTTP відповідь, запис у БД) | Виконати дію |
| **Режим роботи** | Polling з інтервалом (`poke_interval`) або reschedule | Одноразовий запуск |
| **Timeout** | Зупиняється якщо умова не виконана за `timeout` секунд | N/A |
| **Ресурси** | Утримує worker slot (poke mode) або звільняє (reschedule mode) | Виконується і звільняє |

**Приклад у MLOps:**
```python
from airflow.sensors.filesystem import FileSensor

# Чекаємо поки нові дані з'являться у DVC-відстежуваній папці
wait_for_data = FileSensor(
    task_id="wait_for_new_data",
    filepath="/data/raw/new_batch/*.csv",
    poke_interval=300,   # перевіряємо кожні 5 хв
    timeout=3600,        # якщо файл не з'явився за 1 год — fail
    mode="reschedule",   # звільняє worker slot між перевірками
    dag=dag,
)
```

Instead of running training on a schedule, the DAG triggers only when new data arrives.

---

## 11. Поясніть ідемпотентність стосовно задач у DAG. Чому це критично?

**Ідемпотентність** — властивість задачі повертати однаковий результат при повторному запуску з тим самим вхідним станом, не спричиняючи бічних ефектів.

**Чому критично в автоматизованих пайплайнах:**
- Airflow автоматично ретраює невдалі задачі (`retries=3`).
- При збої job на 70% Airflow перезапустить саме ту задачу — не весь DAG.
- Якщо задача **не ідемпотентна** → дублікати записів у БД, подвійна реєстрація моделі, пошкоджені артефакти.

**Приклади ідемпотентних задач:**
```python
# ✅ Ідемпотентно: завжди перезаписує файл
model.save("models/best_model.pkl")  # overwrite

# ✅ Ідемпотентно: MLflow run_id прив'язано до dag_run_id
with mlflow.start_run(run_name=f"ct_{dag_run_id}"):
    ...

# ❌ НЕ ідемпотентно: append замість replace
df.to_csv("results.csv", mode="a")  # кожен запуск додає рядки
```

**Практично в нашому DAG:** задача `train_model` завжди запускає `dvc repro`, який кешує результати за content hash — повторний запуск з тими самими даними поверне кешований артефакт.

---

## 12. Як реалізувати Infrastructure as Code (IaC) у контексті MLOps?

**IaC** — опис інфраструктури (сервери, мережі, сховища) у вигляді версіонованих файлів, аналогічно коду.

**Рівні IaC у нашому проекті:**

| Рівень | Файл | Що описує |
|---|---|---|
| **Контейнери** | `Dockerfile`, `docker-compose.yml` | Середовища виконання |
| **CI/CD** | `.github/workflows/*.yaml` | Пайплайни автоматизації |
| **Залежності** | `pyproject.toml`, `uv.lock` | Python-середовище |
| **Дані** | `dvc.yaml`, `dvc.lock` | Data pipeline + версії даних |
| **Конфігурація** | `conf/config.yaml` (Hydra) | Гіперпараметри, шляхи |

**Для хмарної інфраструктури** (якщо потрібно):
```hcl
# terraform/main.tf
resource "aws_s3_bucket" "dvc_remote" {
  bucket = "mlops-lab-dvc-remote"
}
```

**Переваги IaC:** будь-хто може відтворити повне середовище з нуля командою:
```bash
git clone ...
docker-compose up -d  # Airflow + MLflow
```

---

## 13. У чому різниця між Build Artifact і Model Artifact?

| | **Build Artifact** | **Model Artifact** |
|---|---|---|
| **Що це** | Артефакт software build процесу | ML-модель як результат тренування |
| **Приклади** | Docker image, Python wheel, JAR | `model.pkl`, ONNX-файл, TF SavedModel |
| **Версіонування** | Git tag, Docker tag, pip version | MLflow run_id, DVC hash, model version |
| **Відтворюваність** | Dockerfile + lockfile → ідентичний образ | seed + дані + код → ідентична модель |
| **Сховище** | Container Registry, PyPI, GitHub Packages | MLflow Registry, S3, DVC remote |
| **Термін зберігання** | Версіями, старі видаляються | Довше — для rollback у production |

**У нашій системі:**
- **Build artifact** → Docker image `ml-pipeline:latest`, що будується у CI
- **Model artifact** → `model.pkl` + `metrics.json`, зареєстровані в MLflow Registry

---

## 14. Як забезпечити безпеку конфіденційних даних при використанні CI/CD та оркестраторів?

**Принципи:**
1. **Ніколи не зберігати секрети в Git** — навіть у `.env` файлах.
2. **Різні секрети для різних середовищ** (dev / staging / prod).
3. **Принцип мінімальних привілеїв** — CI/CD токен має лише необхідні права.

**GitHub Actions:**
```yaml
# Секрети зашифровані у Settings → Secrets
env:
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  MLFLOW_TRACKING_TOKEN: ${{ secrets.MLFLOW_TRACKING_TOKEN }}
```

**Apache Airflow:**
```python
# Через Airflow Variables або Connections (зашифровані у Metadata DB)
from airflow.models import Variable

mlflow_uri = Variable.get("MLFLOW_TRACKING_URI")
# Або через Connection:
from airflow.hooks.base import BaseHook
conn = BaseHook.get_connection("mlflow_default")
```

**Docker Compose (локально):**
```yaml
# docker-compose.yml використовує .env (у .gitignore)
services:
  airflow:
    env_file: .env  # AWS_ACCESS_KEY_ID=...
```

**Аудит:** регулярно ротувати токени, використовувати short-lived credentials (наприклад, AWS OIDC замість довготривалих access keys у CI).
