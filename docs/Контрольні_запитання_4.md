# Контрольні запитання - Відповіді (Лабораторна робота №4)

## 1. У чому різниця між CI та CD у контексті ML?

**CI (Continuous Integration)** — автоматична перевірка кожного коміту: лінтинг, тести даних, тренування, Quality Gate. Мета: виявляти проблеми якомога раніше.

**CD (Continuous Delivery/Deployment)** — автоматична підготовка та публікація артефактів після успішного CI:

| | CI | CD |
|---|---|---|
| **Тригер** | Кожен push/PR | Лише після успішного CI на `main` |
| **Результат** | Звіт про якість | Готовий артефакт (model.joblib, registry) |
| **Приклад (ЛР4)** | pytest + cml comment | upload-artifact на GitHub |

---

## 2. Опишіть структуру GitHub Actions Workflow

```
Workflow (.github/workflows/cml.yaml)
└── Triggered by: push / pull_request    ← Event
    └── Job: test-and-report             ← Job (runs on ubuntu-latest Runner)
        ├── Step: Checkout               ← Step
        ├── Step: Setup uv
        ├── Step: Lint with Ruff
        ├── Step: DVC pull
        ├── Step: Pre-train tests
        ├── Step: dvc repro
        ├── Step: Post-train tests
        └── Step: CML report
```

- **Workflow** — YAML файл, описує весь процес
- **Event** — подія запуску (`push`, `pull_request`)
- **Job** — набір кроків на одному runner (кожен job — чистий контейнер)
- **Runner** — VM/контейнер (у нас `ubuntu-latest`)
- **Step** — окрема команда або `uses:` action

---

## 3. Що таке CML і яку проблему він вирішує?

**CML (Continuous Machine Learning)** — CLI-інструмент від Iterative.ai для інтеграції ML-результатів у Git workflow.

**Проблема без CML:** після тренування в CI результати губляться в логах. Ревʼювер не може порівняти метрики без власного запуску.

**З CML:**
```bash
cml publish confusion_matrix.png --md >> report.md
cml comment create report.md   # публікує як коментар у PR
```

Ревʼювер бачить таблицю метрик і графіки прямо у PR — без запуску коду.

---

## 4. Чому важливо розділяти pre-train та post-train тести?

**Pre-train тести** (швидко, без тренування) дають **ранній зворотний зв'язок**:
- Якщо дані некоректні → не витрачати 10 хвилин на тренування
- Перевіряють: форму масивів, діапазони значень, баланс класів, NaN

**Post-train тести** перевіряють результат:
- Чи збережені артефакти (`metrics.json`, `*.joblib`, `confusion_matrix.png`)
- **Quality Gate**: `test_f1 >= 0.80` — формальний критерій допуску моделі

```
pre-train → (fail fast ←) train → post-train → CML report
```

Такий порядок економить час і дає чіткий сигнал про причину збою.

---

## 5. Що таке Quality Gate і чому він важливий?

**Quality Gate** — формалізований поріг, що автоматично вирішує: чи відповідає модель мінімальним вимогам якості.

У нашому проекті (`tests/test_artifacts.py`):
```python
F1_THRESHOLD = 0.80       # test_f1 >= 0.80
ACCURACY_THRESHOLD = 0.75  # test_accuracy >= 0.75
MAX_OVERFITTING_GAP = 0.15 # train_f1 - test_f1 <= 0.15
```

**Навіщо:** якщо хтось змінить `max_depth=1` або сломає preprocessing — PR автоматично відхиляється, а не йде в production. Це замінює ручну перевірку метрик кожного PR.

---

## 6. Як вирішити проблему доступу до даних у CI/CD?

Головна проблема: `data/raw/chest_xray` (~1.2GB) не зберігається в Git, а CI-runner чиста VM без локального DVC-кешу.

**Варіанти:**

| Варіант | Плюси | Мінуси |
|---|---|---|
| **DVC + S3/GCS remote** | Правильний підхід, дані версіоновані | Потрібен хмарний акаунт + secrets |
| **Commit data до Git** | Просто | Порушує DVC-принципи, ліміти GitHub |
| **Кешувати підготовлені дані** | Швидко в CI (лише `data/prepared/`) | Все ще потрібне сховище |

**Наш підхід (ЛР4):** DVC remote на S3, облікові дані через GitHub Secrets:
```yaml
env:
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
```
```bash
uv run dvc pull   # завантажує data/prepared/ та data/raw/
```

---

## 7. Які переваги використання `uv` у CI порівняно з `pip + requirements.txt`?

| | `pip install -r requirements.txt` | `uv sync --frozen` |
|---|---|---|
| **Швидкість** | ~2-3 хв (compile + resolve) | ~10-30 сек (бінарний інстолятор) |
| **Відтворюваність** | requirements.txt може мати `>=` версії | `uv.lock` — точні версії всіх транзитивних залежностей |
| **Кешування** | `cache: pip` на основі requirements.txt | `enable-cache: true` кешує весь .venv |
| **Файл** | Потрібен окремий requirements.txt | Використовує вже наявний `pyproject.toml` + `uv.lock` |

```yaml
- uses: astral-sh/setup-uv@v5
  with:
    enable-cache: true        # кешує .venv між runs
- run: uv sync --frozen       # встановлює точно як у lockfile
- run: uv run pytest tests/   # виконує в тому ж venv
```

---

## 8. Як CI/CD забезпечує відтворюваність ML-експериментів?

Кожен CI-run фіксує і перевіряє:

1. **Код** → `git commit hash` (автоматично у кожному run)
2. **Дані** → `dvc.lock` містить MD5-хеш даних, `dvc pull` відтворює точну версію
3. **Конфігурація** → `conf/config.yaml` (Hydra) у репозиторії
4. **Залежності** → `uv.lock` з точними версіями бібліотек
5. **Seed** → фіксований у `conf/config.yaml` (`random_state: 42`)

**Результат:** будь-хто може взяти будь-який коміт і відтворити той самий результат командою:
```bash
git checkout <commit>
uv sync --frozen
dvc pull
dvc repro
```
