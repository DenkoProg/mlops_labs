# Контрольні запитання - Відповіді (Лабораторна робота №3)

## 1. Яка різниця між параметрами моделі та гіперпараметрами?

**Параметри моделі** — навчаються автоматично під час тренування (наприклад, порогові значення розбиття у деревах Random Forest, ваги нейронної мережі). Ніколи не задаються вручну.

**Гіперпараметри** — задаються *до* навчання і контролюють сам процес навчання або структуру моделі:

| Гіперпараметр | Що контролює |
|---|---|
| `n_estimators` | Кількість дерев у лісі |
| `max_depth` | Максимальна глибина дерева |
| `min_samples_split` | Мінімум зразків для розбиття вузла |
| `C` (LogReg) | Сила регуляризації |

---

## 2. Чому Grid Search погано масштабується зі зростанням кількості гіперпараметрів?

Кількість комбінацій росте **експоненційно** — «прокляття розмірності»:

```
3 параметри × 10 значень кожен = 10³ = 1000 комбінацій
5 параметрів × 10 значень кожен = 10⁵ = 100 000 комбінацій
```

При цьому більшість комбінацій є неперспективними. На відміну від Grid Search, Bayesian Optimization (TPE) розумно обирає наступні точки на основі вже отриманих результатів, що дозволяє знаходити хороші параметри за значно меншу кількість спроб.

---

## 3. Поясніть принцип роботи TPE (Tree-structured Parzen Estimator)

TPE розділяє результати спроб на дві групи за заданим квантилем (за замовчуванням 25% кращих):

- **l(x)** — розподіл параметрів серед «хороших» trial-ів
- **g(x)** — розподіл серед «поганих» trial-ів

Наступна точка обирається там, де **l(x)/g(x)** максимальний — тобто де параметри частіше зустрічаються у хороших результатах і рідко у поганих. Це забезпечує баланс між exploitation (досліджувати відомо хороші зони) та exploration (пробувати нові).

---

## 4. Що таке Study і Trial в Optuna?

**Study** — «контейнер» всієї оптимізаційної кампанії. Зберігає всі trial-и, їх параметри, результати та стан семплера.

**Trial** — одна спроба: конкретний набір гіперпараметрів → запуск → одне значення метрики.

```python
# У нашому проекті:
study = optuna.create_study(
    direction="maximize",          # максимізуємо test_f1
    sampler=TPESampler(seed=42),   # відтворюваний TPE
)
study.optimize(objective, n_trials=20)  # 20 trials

# Результат:
# Best trial #3: test_f1=0.8823
# Params: n_estimators=227, max_depth=5, min_samples_split=20
```

---

## 5. Навіщо використовувати nested runs у MLflow при HPO?

Без nested runs 20 trial-ів і фінальний запуск виглядали б як 21 незалежний run — незрозуміло, які пов'язані між собою. Nested runs дають ієрархічну структуру:

```
hpo_study (parent run)
├── trial_0  (child run) — n_estimators=180, max_depth=12 → f1=0.86
├── trial_1  (child run) — n_estimators=67,  max_depth=28 → f1=0.83
├── trial_2  (child run) — ...
│   ...
└── trial_19 (child run) — n_estimators=227, max_depth=5  → f1=0.88 ✅
```

На parent run логуються `best_n_estimators`, `best_test_f1` — підсумок всього HPO.

---

## 6. Як гарантувати відтворюваність Optuna Study?

Фіксуємо seed у семплері:
```python
sampler = optuna.samplers.TPESampler(seed=42)
study = optuna.create_study(sampler=sampler)
```
Тоді при повторному запуску з тим самим seed і тими самими даними — послідовність параметрів у trial-ах буде ідентичною. В нашому проекті seed задається через Hydra config (`conf/config.yaml`), що робить його частиною зафіксованої конфігурації:

```yaml
optuna:
  seed: 42
```

---

## 7. Що таке pruner у Optuna і коли його варто використовувати?

**Pruner** — механізм ранньої зупинки поганих trial-ів на основі проміжних результатів. Замість того щоб чекати повного навчання для явно безперспективної спроби, pruner зупиняє її достроково.

**Коли використовувати:**
- Навчання займає багато часу (нейронні мережі, XGBoost з великою кількістю раундів)
- Є можливість отримувати проміжні метрики (по epochs чи раундам)

**Для нашого Random Forest** pruner не застосовується, оскільки RF навчається в один прохід без проміжних результатів.

Приклад з Hyperband Pruner для нейронних мереж:
```python
study = optuna.create_study(
    pruner=optuna.pruners.HyperbandPruner()
)
```

---

## 8. Інтерпретуйте результати HPO вашого проекту: компроміс якість ↔ ресурси

**Результат оптимізації:**
- **До HPO** (фіксовані параметри): `test_f1 = 0.8515`, `max_depth=15`, `n_estimators=100`
- **Після HPO** (best trial #3): `test_f1 = 0.8823`, `max_depth=5`, `n_estimators=227`

**Що це означає:**
- `max_depth=5` (менша глибина) → модель стала **менш схильна до перенавчання**: `final_train_f1=0.9668` vs `0.9974` раніше, а `test_f1` зріс з `0.8515` → `0.8823`
- `n_estimators=227` → більше дерев компенсує меншу глибину кожного, стабілізуючи передбачення

**Компроміс:**
- Час навчання фінальної моделі зріс (~2.2x більше дерев)
- Але якість test_f1 покращилась на **+3.6%** — суттєво для медичної задачі (PNEUMONIA detection)

> **Висновок:** HPO показав, що «неглибокий але широкий» ансамбль кращий за «глибокий і вузький» на цьому датасеті. Глибокі дерева перенавчалися на тренувальних даних.
